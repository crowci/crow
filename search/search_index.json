{"config":{"lang":["en"],"separator":"[\\s\\u200b\\-_,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Getting started","text":"<p>Crow CI is a Continuous Integration &amp; Continuous Delivery (CI/CD)<sup>1</sup> application. It is designed to be lightweight, simple to use and fast.</p>"},{"location":"#why-self-host-cicd","title":"Why self-host CI/CD?","text":"<p>There are many CI/CD options offered for free. As with all hosted options which are provided for free, there are limitations and downsides. Self-hosting provides ways to get rid of these.</p> <p>For CI/CD specifically, the following limitations of public CI offerings can be tackled:</p> <ul> <li>Limited build times</li> <li>Low-performing runners</li> <li>Storing secrets on remote platforms</li> <li>Platform/Forge bound</li> </ul>"},{"location":"#why-use-crow-ci-in-the-first-place","title":"Why use Crow CI in the first place?","text":"<p>Crow CI gives you full control over the selection of nodes which will process builds. You can store secrets on servers you own and run as many builds as you want. In addition, Crow CI works with many different forges (GitHub, GitLab, Gitea, Forgejo, Bitbucket), allowing you to transition between these or use a consistent CI syntax across all of them.</p> <p>Combined with the Crow CI Autoscaler, you can make use of powerful CI runners on any cloud provider, giving you the full power the cloud space has to offer while keeping costs to a minimum.</p>"},{"location":"#containers-at-the-core","title":"Containers at the core","text":"<p>Crow CI is a container-only application. This stands in contrast to other common CI/CD apps like GitHub Actions, GitLab Runner, Jenkins, Circle CI or Drone CI. While these can also execute pipelines in containers if desired, they are \"host-first\", i.e., by default pipelines run directly on a VM and are subsequently restricted to the OS on that VM.</p> <p>Crow in contrast only uses containers and is hence operating-system agnostic, i.e. it does not matter which OS is running on the host which is executing the pipelines.</p> <p>With respect to well-known CI/CD providers, Crow is mostly comparable to Circle CI, which is also makeing use of a container-only approach.</p>"},{"location":"#target-audience","title":"Target audience","text":"<p>Crow CI is Apache-2.0 licensed, lightweight and can be used in private environments without restriction. It has a very small footprint (&lt; 200 MB memory consumption) in idle and can even be installed and practically used on a Raspberry Pi with 4GB (or even less, depending on what the builds will do).</p> <p>Crow uses a SQLite by default and can do a lot with in during runtime. If you are planning a bigger instance with multiple (active) users and &gt; 20 active repos, it is recommended to configure it with a Postgres or MariaDB database for performance reasons.<sup>2</sup></p>"},{"location":"#history","title":"History","text":"<p>Crow has been forked from Woodpecker CI (v3.0.0) in January 2025 from the former Woodpecker maintainer @pat-s. Motivation for the fork was built around the improvement of infrastructure-related processes (releases, docs, governance) and professionalizing the project ecosystem.</p> <p>Woodpecker itself is a fork of Drone CI (v0.8.91) from April 2019 with the first standalone version being released on September 9th 2019.</p>"},{"location":"#license","title":"License","text":"<p>Crow CI is licensed under the Apache 2.0 license (following inheritance from Woodpecker and Drone).</p>"},{"location":"#logo","title":"Logo","text":"<p>The logo was designed and kindly contributed by Bold Crow AI.</p> <ol> <li> <p>This RedHat blog post explains the concept of CI/CD in more detail. \u21a9</p> </li> <li> <p>This is primarily because Crow (still) stores pipeline logs in the DB. A refactoring to storing these outside the DB by default is planned but now yet implemented.\u00a0\u21a9</p> </li> </ol>"},{"location":"configuration/","title":"Index","text":"<p>All configuration is done through via environment variables. These pages describe the configuration of Server, Agent and the optional Autoscaler in greater detail.</p> <p>A list of all existing environment variables is available at \"All environment variables\".</p>"},{"location":"configuration/agent/","title":"Agent","text":"<p>To configure an agent, the following settings are required at a minimum:</p> <pre><code>CROW_SERVER=&lt;connection uri&gt; # usually 'e.g. woodpecker-server:9000'\nCROW_AGENT_SECRET=\"&lt;token&gt;\"\n</code></pre>"},{"location":"configuration/agent/#workflows-per-agent","title":"Workflows per agent","text":"<p>Note</p> <p>A pipeline often consists of multiple workflows. It is recommended therefore to increase this setting to a value matching the resources of the surrounding environment (i.e. if builds are executed on a server with 4GB memory, allowing 100 workflows in parallel is likely not a good match).</p> <p>By default, every agent is allowed to execute on workflow at a time. This can be controlled via <code>CROW_MAX_WORKFLOWS</code> to increase the amount of parallel workflows an agent is allowed to process.</p>"},{"location":"configuration/agent/#workflow-filters","title":"Workflow filters","text":"<p>Agents can be configured to only process workflows of certain repositories.</p> <pre><code>CROW_AGENT_LABELS=repo=&lt;username&gt;/*\n</code></pre> <p>This config would restrict an agent to builds of this particular namespace (being it an org or user). This could be used together with the deployment of the agent on a specific server, and by this isolating specific pipelines from others.</p>"},{"location":"configuration/autoscaler/","title":"Autoscaler","text":""},{"location":"configuration/autoscaler/#preface-what-is-the-crow-ci-autoscaler","title":"Preface: What is the 'Crow CI Autoscaler'?","text":"<p>The Crow CI Autoscaler is a standalone application which will spin up servers in a configured cloud provider to execute Crow CI pipelines. After the VM is ready, it will create a Crow CI agent that will pick up pending pipeline jobs.</p> <p>If no new builds are in the queue, the Autoscaler will wait a bit (default 10 mins) and then remove the server again.</p> <p>The app allows you to utilize powerful servers on-demand and terminate them immediately after use. This minimizes costs and prevents the expense of maintaining large idle instances when no builds are running.</p> <p>The Crow CI Autoscaler currently works with the following cloud providers:</p> <ul> <li>AWS</li> <li>Hetzner Cloud</li> <li>Linode</li> <li>Scaleway</li> <li>Vultr</li> </ul> <p>More providers which provide a golang SDK can be added - contributions welcome!</p>"},{"location":"configuration/autoscaler/#installation","title":"Installation","text":"<p>The autoscaler should be installed alongside the server instance as it listens for build triggers of it. To connect to it, it needs to know the server address (<code>CROW_SERVER</code>) and an API token (<code>CROW_TOKEN</code>). The token is used to add and remove agents from the server and must be from an admin user.</p> <pre><code>[...]\n  crow-autoscaler:\n    image: ghcr.io/crowci/crow-autoscaler:&lt;tag&gt;\n    restart: always\n    depends_on:\n      - crow-server\n    environment:\n      - CROW_SERVER=crow-server:9000 # can also be the public URL (https://)\n      - CROW_TOKEN=${CROW_TOKEN}\n</code></pre>"},{"location":"configuration/autoscaler/#configuration","title":"Configuration","text":"<p>Next, the autoscaler configuration must be set. You need to define how the scaling should work, i.e. how many servers are allowed to be provisioned and how many (if any) should be running at all times.</p> <p>Often, allowing only one powerful server is enough, as this one will be able to process many poipelines in parallel (if the chosen instance type has enough resources).</p> <p>Similary, <code>CROW_WORKFLOWS_PER_AGENT</code> defines how many workflows can be processed in parallen for each agent (each server has its own unique agent). A good value for this setting depends on the resources of the server and the jobs which run on it, hence it is not possible to give a general recommendation that would fit all use cases.</p> <p>Tip</p> <p>Monitor the resource usage of the first builds and see how many resources are needed. Then adjust the autoscaler settings accordingly.</p> <pre><code>[...]\n  crow-autoscaler:\n    image: ghcr.io/crowci/crow-autoscaler:&lt;tag&gt;\n    restart: always\n    depends_on:\n      - crow-server\n    environment:\n      - CROW_SERVER=crow-server:9000 # can also be the public URL (https://)\n      - CROW_TOKEN=${CROW_TOKEN}\n      - CROW_MIN_AGENTS=0\n      - CROW_MAX_AGENTS=1\n      - CROW_WORKFLOWS_PER_AGENT=5\n</code></pre>"},{"location":"configuration/autoscaler/#grpc-connection-between-agent-and-server","title":"GRPC connection between agent and server","text":"<p>The next required step is to provide the GRPC connection information which the agent is going to use to connect to the server. Remember, the agent will be running on a standalone server and must be able to connect to the crow server instance over a public connection. To do so securely, a SSL-backed connection is required. This requires the server which is running the crow server instance to listen for incoming grpc requests.</p> <p>To achieve this, two components are required:</p> <ul> <li>A reverse proxy listening on a https connection</li> <li>Forwarding of incoming requests to the grpc port of the crow server instance</li> </ul> <p>We'll discuss how this can be done further below.</p> <p>Coming back to the settings which need to be passed to the autoscaler. Setting <code>WOODEPCKER_GRPC_SECURE</code> is telling the upcoming agent to use SSL for all GRPC-based connections (by default it does not as usually the agent is on the same server as the crow server instance). In addition, it needs to know where to connect to, which is why <code>WOODEPCKER_GRPC_ADDR</code> is pointing to the public GRPC address of the server instance.</p> <pre><code>[...]\n  crow-autoscaler:\n    image: ghcr.io/crowci/crow-autoscaler:&lt;tag&gt;\n    restart: always\n    depends_on:\n      - crow-server\n    environment:\n      - CROW_SERVER=crow-server:9000 # can also be the public URL (https://)\n      - CROW_TOKEN=${CROW_TOKEN}\n      - CROW_MIN_AGENTS=0\n      - CROW_MAX_AGENTS=1\n      - CROW_WORKFLOWS_PER_AGENT=5\n      - WOODEPCKER_GRPC_ADDR=https://grpc.your-crow-server.com # must be a public URL\n      - WOODEPCKER_GRPC_SECURE=true\n</code></pre>"},{"location":"configuration/autoscaler/#cloud-provider-configuration","title":"Cloud provider configuration","text":"<p>The last step is to tell the autoscaler which cloud provider to use. This is done by setting <code>CROW_PROVIDER</code> and providing a token to authenticate. The naming of this env var and the related provider-specific ones vary, depending on the features the provider offers.</p> <pre><code>[...]\n  crow-autoscaler:\n    image: ghcr.io/crowci/crow-autoscaler:&lt;tag&gt;\n    restart: always\n    depends_on:\n      - crow-server\n    environment:\n      - CROW_SERVER=crow-server:9000 # can also be the public URL (https://)\n      - CROW_TOKEN=${CROW_TOKEN}\n      - CROW_MIN_AGENTS=0\n      - CROW_MAX_AGENTS=1\n      - CROW_WORKFLOWS_PER_AGENT=5\n      - CROW_GRPC_ADDR=https://grpc.your-crow-server.com # must be a public URL\n      - CROW_GRPC_SECURE=true\n      - CROW_PROVIDER=hetznercloud\n      - CROW_HETZNERCLOUD_API_TOKEN=${CROW_HETZNERCLOUD_API_TOKEN}\n      - CROW_HETZNERCLOUD_LOCATION='fsn1' # Falkenstein\n      - CROW_HETZNERCLOUD_SERVER_TYPE='cax41' # 16 cores, 32 GB RAM\n      - CROW_HETZNERCLOUD_IMAGE='ubuntu-24.04'\n      - CROW_HETZNERCLOUD_NETWORKS='&lt;network name&gt;'\n      - CROW_HETZNERCLOUD_SSH_KEYS='&lt;key name&gt;'\n      - CROW_HETZNERCLOUD_FIREWALLS='&lt;firewall name&gt;'\n</code></pre>"},{"location":"configuration/autoscaler/#agent-timeout-removal","title":"Agent timeout &amp; removal","text":"<p>There are two types of timeouts which can be set for the autoscaler</p> <ul> <li><code>CROW_AGENT_IDLE_TIMEOUT</code> defines how long an agent is allowed to be idle before it is removed.</li> <li><code>CROW_AGENT_SERVER_CONNECTION_TIMEOUT</code> defines how long an agent is kept alive after the last successful connection to the server has been established.</li> </ul> <p>The first option is responsible for how long a server is being kept alive after the last build has been processed.</p> <p>The second one is primarily a safety fallback for agents which are not able to communicate with the server anymore, for whatever reason (most likely due to a configuration issue). In this case, the autoscaler will recognize this and shut down the instance to avoid infinite reconnection tries.</p> <pre><code>[...]\n  crow-autoscaler:\n    image: ghcr.io/crowci/crow-autoscaler:&lt;tag&gt;\n    restart: always\n    depends_on:\n      - crow-server\n    environment:\n      - CROW_SERVER=crow-server:9000 # can also be the public URL (https://)\n      - CROW_TOKEN=${CROW_TOKEN}\n      - CROW_MIN_AGENTS=0\n      - CROW_MAX_AGENTS=1\n      - CROW_WORKFLOWS_PER_AGENT=5\n      - CROW_GRPC_ADDR=https://grpc.your-crow-server.com # must be a public URL\n      - CROW_GRPC_SECURE=true\n      - CROW_PROVIDER=hetznercloud\n      - CROW_HETZNERCLOUD_API_TOKEN=${CROW_HETZNERCLOUD_API_TOKEN}\n      - CROW_HETZNERCLOUD_LOCATION='fsn1' # Falkenstein\n      - CROW_HETZNERCLOUD_SERVER_TYPE='cax41' # 16 cores, 32 GB RAM\n      - CROW_HETZNERCLOUD_IMAGE='ubuntu-24.04'\n      - CROW_HETZNERCLOUD_NETWORKS='&lt;network name&gt;'\n      - CROW_HETZNERCLOUD_SSH_KEYS='&lt;key name&gt;'\n      - CROW_HETZNERCLOUD_FIREWALLS='&lt;firewall name&gt;'\n      - CROW_AGENT_IDLE_TIMEOUT=10m\n      - CROW_AGENT_SERVER_CONNECTION_TIMEOUT=10m\n</code></pre>"},{"location":"configuration/autoscaler/#generic-agent-configuration","title":"Generic agent configuration","text":"<p>Last, there is the option to set arbitrary agent env vars via <code>CROW_AGENT_ENV</code>. This can be helpful to control logging and other agent-specific settings. The values must be passedn as a comma-separated list:</p> <pre><code>CROW_AGENT_ENV: CROW_HEALTHCHECK=false,CROW_LOG_LEVEL=debug\n</code></pre>"},{"location":"configuration/autoscaler/#grpc-proxy-configuration","title":"GRPC proxy configuration","text":"<p>As mentioned above, the GRPC connection between the agent and the server needs to be secured. This is done by setting up a reverse proxy which listens on a https connection and forwards incoming requests to the grpc port of the crow server instance.</p> <p>In the following examples for different reverse proxies are shown. These are only minimal examples and you usually want to set additional headers and other options to secure the connection further.</p> <p>Note</p> <p>The SSL certificate can be created like any other certificate for public servers. Let's Encrypt is a good choice for this.</p>"},{"location":"configuration/autoscaler/#nginx","title":"Nginx","text":"<pre><code>server {\n    listen 443 ssl http2;\n    server_name grpc.your-crow-server.com;\n\n    ssl_certificate /etc/ssl/certs/your-crow-server.com.crt;\n    ssl_certificate_key /etc/ssl/private/your-crow-server.com.key;\n\n    location / {\n        grpc_pass grpc://crow-server:9000;\n    }\n}\n</code></pre>"},{"location":"configuration/autoscaler/#caddy","title":"Caddy","text":"<pre><code>grpc.your-crow-server.com {\n    reverse_proxy grpc://crow-server:9000\n    tls /etc/ssl/certs/your-crow-server.com.crt /etc/ssl/private/your-crow-server.com.key\n}\n</code></pre>"},{"location":"configuration/autoscaler/#traefik","title":"Traefik","text":"<pre><code>http:\n  routers:\n    grpc:\n      rule: Host(`grpc.your-crow-server.com`)\n      service: crow-server\n      tls:\n        certResolver: your-crow-server.com\n  services:\n    crow-server:\n      loadBalancer:\n        servers:\n          - url: http://crow-server:9000\n</code></pre>"},{"location":"configuration/env-vars/","title":"All environment variables","text":""},{"location":"configuration/env-vars/#server","title":"Server","text":"Name Description Value <code>CROW_BACKEND_K8S_NAMESPACE</code> The k8s namespace to execute pipelines in <code>crow</code> <code>CROW_BACKEND_K8S_POD_ANNOTATIONS</code> Additional annotations to apply to worker Pods. Must be a YAML object, e.g. <code>{\"example.com/test-annotation\":\"test-value\"}</code>. <code>CROW_BACKEND_K8S_POD_LABELS_ALLOW_FROM_STEP</code> Determines if Pod annotations can be defined from a step's backend options. <code>false</code> <code>CROW_BACKEND_K8S_POD_LABELS</code> Additional labels to apply to worker Pods. Must be a YAML object, e.g. <code>{\"example.com/test-label\":\"test-value\"}</code> <code>CROW_BACKEND_K8S_POD_NODE_SELECTOR</code> Additional node selector to apply to worker pods. Must be a YAML object, e.g. <code>{\"topology.kubernetes.io/region\":\"eu-central-1\"}</code> <code>CROW_BACKEND_K8S_PULL_SECRET_NAMES</code> Secret names to pull images from private repositories. <code>CROW_BACKEND_K8S_SECCTX_NONROOT</code> Whether containers must be run as a non-root user. <code>false</code> <code>CROW_BACKEND_K8S_STORAGE_CLASS</code> The storage class to use for the temporary pipeline volume. <code>CROW_BACKEND_K8S_STORAGE_RWX</code> Whether a RWX should be used for the temporary pipeline volume. If false, RWO is used instead. <code>true</code> <code>CROW_BACKEND_K8S_STORAGE_CLASS</code> The storage class to use for the pipeline volume. <code>CROW_BACKEND_K8S_VOLUME_SIZE</code> The volume size of the temporary pipeline volume. <code>10G</code> <code>CROW_BACKEND_LOCAL_TEMP_DIR</code> Directory in which pipelines are executed <code>$TMPDIR</code> <code>CROW_LOG_LEVEL</code> Logging level. Possible values are <code>trace</code>, <code>debug</code>, <code>info</code>, <code>warn</code>, <code>error</code>, <code>fatal</code>, <code>panic</code>, and <code>disabled</code>. <code>CROW_LOG_FILE</code> Output destination for logs. <code>stdout</code> and <code>stderr</code> can be used as special keywords. <code>stderr</code>"},{"location":"configuration/env-vars/#agent","title":"Agent","text":"Name Description Value <code>CROW_AGENT_CONFIG_FILE</code> Filepath containing agent config, e.g. <code>/etc/woodpecker/agent.conf</code> <code>CROW_AGENT_LABELS</code> Configures custom labels for the agent, to enable workflow filtering. Accepts a list of key-value pairs like <code>key=value,second-key=*</code>. Agents provide three additional labels  <code>platform=os/arch</code>, <code>hostname=my-agent</code> and <code>repo=*</code>  which can be overwritten if needed. <code>CROW_AGENT_SECRET_FILE</code> Filepath containing agent secret, e.g. <code>/etc/woodpecker/agent-secret.conf</code> <code>CROW_AGENT_SECRET</code> A shared secret used by server and agents to authenticate communication. A secret can be generated via <code>openssl rand -hex 32</code>. <code>CROW_BACKEND</code> Woodpecker backend to use. Possible values are <code>auto-detect</code>, <code>docker</code>, <code>local</code> or <code>kubernetes</code>. <code>auto-detect</code> <code>CROW_CONNECT_RETRY_COUNT</code> number of times agent retries to connect to the server. <code>5</code> <code>CROW_CONNECT_RETRY_DELAY</code> delay between agent connection retries to the server. <code>2s</code> <code>CROW_DEBUG_NOCOLOR</code> Disable colored debug output. <code>true</code> <code>CROW_DEBUG_PRETTY</code> Enable pretty-printed debug output. <code>false</code> <code>CROW_GRPC_SECURE</code> Whether the connection to <code>CROW_SERVER</code> should be made via SSL. <code>false</code> <code>CROW_GRPC_VERIFY</code> Whether the <code>grpc</code> server certificate should be verified. Only valid when <code>CROW_GRPC_SECURE=true</code>. <code>true</code> <code>CROW_HEALTHCHECK_ADDR</code> Healthcheck endpoint address. <code>:3000</code> <code>CROW_HEALTHCHECK</code> Enable healthcheck endpoint. <code>true</code> <code>CROW_HOSTNAME</code> Agent hostname <code>CROW_KEEPALIVE_TIME</code> With no activity after this duration, the agent pings the server  to check if the transport is still alive. <code>CROW_KEEPALIVE_TIMEOUT</code> After pinging for a keepalive check, the agent waits for this duration before closing unresponsive connections. <code>20s</code> <code>CROW_LOG_LEVEL</code> Logging level. Possible values are <code>trace</code>, <code>debug</code>, <code>info</code>, <code>warn</code>, <code>error</code>, <code>fatal</code>, <code>panic</code>, and <code>disabled</code>. <code>CROW_MAX_WORKFLOWS</code> Number of parallel workflows. <code>1</code> <code>CROW_SERVER</code> gRPC address of the server. <code>localhost:9000</code> <code>CROW_USERNAME</code> gRPC username. <code>x-oauth-basic</code> <code>CROW_LOG_FILE</code> Output destination for logs. <code>stdout</code> and <code>stderr</code> can be used as special keywords. <code>stderr</code>"},{"location":"configuration/server/","title":"Server","text":""},{"location":"configuration/server/#forge-user-configuration","title":"Forge &amp; User configuration","text":"<p>Crow can only be used in combination with a \"Forge\" (i.e. Git Provider). The following ones are currently supported:</p> <ul> <li>GitHub</li> <li>GitLab</li> <li>Gitea</li> <li>Forgejo</li> <li>Bitbucket Datacenter</li> </ul> <pre><code>CROW_FORGE=github # gitlab,gitea,forgejo,bitbucket\n</code></pre> <p>As Crow does not have its own user registry, users are provided from the linked forge via OAuth2. There is no way to register users manually.</p> <p>Registration is closed by default (<code>CROW_OPEN=false</code>). If registration is open (<code>CROW_OPEN=true</code>) then every user with an account at the configured forge can login and by this register an account.</p> <p>Warning</p> <p>It is highly recommended to restrict login to a specific subset of users, e.g. members of an organization. Otherwise, there is no control about who can register and create repositories to run pipelines. This is also recommended for private Crow instances. Org-based restrictions can be done by setting <code>CROW_ORGS</code>:</p> <pre><code>```yaml\nCROW_ORGS=org1\n```\n\nThis would limit the use of Crow to member of this organization, allowing administrative control about users.\n</code></pre>"},{"location":"configuration/server/#admin-users","title":"Admin users","text":"<pre><code>CROW_ADMIN=johnDoe,janeSmith\n</code></pre> <p>Besides setting this env var, admins can also be promoted manually in the UI by existing admins (<code>Settings -&gt; Users -&gt; Edit User</code>).</p>"},{"location":"configuration/server/#database","title":"Database","text":""},{"location":"configuration/server/#sqlite","title":"SQLite","text":"<p>Crow uses a SQLite database stored under <code>/var/lib/CROW/</code>.</p> <p>When using the docker-compose installation, make sure to persist (and backup) the volume serving this directory.</p>"},{"location":"configuration/server/#postgres","title":"Postgres","text":"<p>Postgres &gt;= 11 is currently supported.</p> <pre><code>CROW_DATABASE_DRIVER=postgres\nCROW_DATABASE_DATASOURCE=postgres://&lt;user&gt;:&lt;pw&gt;@0.0.0.0:5432/&lt;dbname&gt;?sslmode=disable\n</code></pre>"},{"location":"configuration/server/#mysqlmariadb","title":"MySQL/MariaDB","text":"<p>The minimum version of MySQL/MariaDB required is determined by the <code>go-sql-driver/mysql</code> - see its README for more information.</p> <pre><code>CROW_DATABASE_DRIVER=mysql\nCROW_DATABASE_DATASOURCE=&lt;user&gt;:&lt;pw&gt;@tcp(0.0.0.0:3306)/&lt;dbname&gt;?parseTime=true\n</code></pre>"},{"location":"configuration/server/#migration","title":"Migration","text":"<p>Crow automatically handles database migrations, i.e. when the schema changes in a new version, the changes are applied during version upgrade. This also means that reverting to an old version after such a migration is not supported.</p>"},{"location":"configuration/server/#backend","title":"Backend","text":"<p>The backend specifies how and where builds are executed. There are two production-grade backends:</p> <ul> <li><code>docker</code></li> <li><code>kubernetes</code></li> </ul> <p>In addition, the <code>local</code> backends exists which allows executing pipelines on the local machine that runs the agent directly.</p> <p>Warning</p> <p>the <code>local</code> backend is aimed at local debugging and development and should not be used in production.</p> <p>Info</p> <p>Podman is not supported as a backend and cannot be used as a backend engine for the \"docker\" backend. This backend needs a dedicated integration using the podman-specific golang libraries. Contributions welcome!</p>"},{"location":"configuration/server/#docker","title":"Docker","text":"<p>The <code>docker</code> backend can be seen as the \"default\" backend. It executes each step inside a separate container started on the agent.</p>"},{"location":"configuration/server/#backend-options","title":"Backend Options","text":"<p>The following <code>backend_options</code> are available:</p> <pre><code>steps:\n  - name: test\n  [...]\n    backend_options:\n      docker:\n        # same as 'docker run --user'\n        user:\n</code></pre>"},{"location":"configuration/server/#housekeeping","title":"Housekeeping","text":"<p>Crow will not automatically clean up images from the Docker installation on the host. Doing so needs extra configuration and should be included as a regular system maintenance task.</p> <p>Here are a few helper commands related to image cleanup:</p> <p>Removing all unused images:</p> <pre><code>docker image rm $(docker images --filter \"dangling=true\" -q --no-trunc)\n</code></pre> <p>Removing dangling/unused Crow volumes:</p> <pre><code>docker volume rm $(docker volume ls --filter name=^crow_* --filter dangling=true -q)\n</code></pre> <p>Pruning all images older than 30 days if the underlying file system partition has reached a certain size:</p> <pre><code># prune when disk usage &gt; 300GB\ndf -k | grep -E '/var/lib/docker$' | awk '{if ($3 &gt; 300000000) system(\"docker image prune -f -a --filter until=720h\")}'\n</code></pre>"},{"location":"configuration/server/#kubernetes","title":"Kubernetes","text":"<p>The Kubernetes backend executes steps inside standalone Pods. For every pipeline, a temporary PVC is created for the lifetime of the pipeline to transfer files between steps.</p> <p>Every step is executed in a distinct pod. This allows every step to be run on a different node, ensuring maximum flexibility with respect to resource distribution.</p> <p>Info</p> <p>There are plans to add a \"one pod per pipeline\" setting which executes all steps as containers of a single pod. This has the advantage of not requiring a RWX volume for file persistence between pods but would at the same time reduce the scheduling flexibility (as it would require the pod to be scheduled on a node that can take the step with the higher resource need).</p>"},{"location":"configuration/server/#private-registries","title":"Private Registries","text":"<p>Images from private registries require authentication. This is commonly done by providing a <code>imagePullSecret</code> in Kubernetes.</p> <p>To do so, the env var <code>CROW_BACKEND_K8S_PULL_SECRET_NAMES</code> can be used. It references existing Kubernetes secrets which contain registry pull secrets and allows the <code>agent</code> to make use of these in a specific namespace (defined via <code>CROW_BACKEND_K8S_NAMESPACE</code>) during pipeline creation.</p> <p>The Kubernetes secret must be of type <code>kubernetes.io/dockerconfigjson</code> and look like:</p> <pre><code>.dockerconfigjson: '{\"auths\":{\"https://index.docker.io/v1/\":{\"auth\":\"&lt;auth&gt;\",\"password\":\"&lt;pw&gt;\",\"username\":\"&lt;username&gt;\"}}}'\n</code></pre> <p>Tip</p> <p>The secret value can be obtained by issuing a local login to the registry and then extracting the created config value from <code>~/.docker/config.json</code>.</p>"},{"location":"configuration/server/#backend-options_1","title":"Backend options","text":"<p>The Kubernetes backend allows specifying requests and limits on a per-step basic, most commonly for CPU and memory.</p> <p>Note</p> <p>Adding a <code>resources</code> definition to all steps is essential for the Kubernetes backend to ensure efficient scheduling.</p>"},{"location":"configuration/server/#general","title":"General","text":"<pre><code>steps:\n  - name: 'Kubernetes step'\n    image: alpine\n    commands:\n      - echo \"Hello world\"\n    backend_options:\n      kubernetes:\n        resources:\n          requests:\n            memory: 200Mi\n            cpu: 100m\n          limits:\n            memory: 400Mi\n            cpu: 1000m\n</code></pre> <p>The following other common pod settings in Kubernetes are supported in <code>backend_options</code> using the same syntax as in Kubernetes:</p> <ul> <li>nodeSelector</li> <li>volumes</li> <li>tolerations</li> <li>securityContext</li> <li>annotations</li> <li>labels</li> </ul> <p>If your unfamiliar with some, please check the corresponding upstream documentation in Kubernetes.</p>"},{"location":"configuration/server/#noteworthy-options-and-adaptations","title":"Noteworthy options and adaptations","text":"<p>In the following, special/uncommon settings are explained in more detail.</p> <ul> <li> <p>Limit Ranges can be used to set the limits by per-namespace basis.</p> </li> <li> <p><code>runtimeClassName</code> specifies the name of the <code>RuntimeClass</code> which will be used to run the Pod.   If <code>runtimeClassName</code> is not set, the default <code>RuntimeHandler</code> will be used.   See the Kubernetes documentation on runtime classes for more information.</p> </li> <li> <p>To allow annotations and labels, the env var <code>crow_BACKEND_K8S_POD_ANNOTATIONS_ALLOW_FROM_STEP</code> and/or <code>crow_BACKEND_K8S_POD_LABELS_ALLOW_FROM_STEP</code> must be set to <code>true</code>.</p> </li> <li> <p>Users of crio-o need to configure the workspace for all pipelines centrally in order ensure correct execution (see this issue):</p> </li> </ul> <pre><code>workspace:\nbase: '/crow'\npath: '/'\n</code></pre>"},{"location":"configuration/server/#local","title":"Local","text":"<p>Danger</p> <p>The local backend executes pipelines on the local system without any isolation.</p> <p>Note</p> <p>This backend does not support 'services'.</p> <p>This backend should only be used in private environments where the code and pipeline can be trusted. It should not be used for public instances where unknown users can add new repositories and execute code. The agent should not run as a privileged user (root).</p> <p>The backend will use a random directory in <code>$TMPDIR</code> to store the cloned code and execute commands.</p> <p>In order to use this backend, a binary of the agent must be built and made executable on the respective server.</p> <p>The backend can be used by setting</p> <pre><code>CROW_BACKEND=local\n</code></pre> <p>The entrypoint of the <code>image:</code> definition in the pipeline is used to declare the shell, such as <code>bash</code> or <code>fish</code>.</p> <p>Plugins are supported and executed as expected. In the context of the <code>local</code> backend, plugins are effectively executable binaries, which can be located using their name if available in <code>$PATH</code>, or through an absolute path:</p> <pre><code>steps:\n  - name: build\n    image: /usr/bin/tree\n</code></pre>"},{"location":"configuration/server/#metrics","title":"Metrics","text":""},{"location":"configuration/server/#endpoint","title":"Endpoint","text":"<p>Crow exposes a Prometheus-compatible <code>/metrics</code> endpoint protected by the environment variable <code>CROW_PROMETHEUS_AUTH_TOKEN</code>.</p> <pre><code>global:\n  scrape_interval: 60s\n\nscrape_configs:\n  - job_name: 'crow'\n    bearer_token: dummyToken...\n\n    static_configs:\n      - targets: ['crow.domain.com']\n</code></pre>"},{"location":"configuration/server/#authorization","title":"Authorization","text":"<p>To access the endpoint, a user-level API token must be created by an admin and handed over in the Prometheus configuration file as a bearer token:</p> <pre><code> global:\n   scrape_interval: 60s\n\n scrape_configs:\n   - job_name: 'crow'\n+    bearer_token: &lt;token&gt;\n\n     static_configs:\n        - targets: ['crow.domain.com']\n</code></pre> <p>Alternatively, the token can be read from a file:</p> <pre><code> global:\n   scrape_interval: 60s\n\n scrape_configs:\n   - job_name: 'crow'\n+    bearer_token_file: /etc/secrets/crow-monitoring-token\n\n     static_configs:\n        - targets: ['crow.domain.com']\n</code></pre>"},{"location":"configuration/server/#reference","title":"Reference","text":"<p>The following metrics are exposed:</p> <pre><code># HELP crow_pipeline_count Pipeline count.\n# TYPE crow_pipeline_count counter\ncrow_pipeline_count{branch=\"main\",pipeline=\"total\",repo=\"crow-ci/crow\",status=\"success\"} 3\ncrow_pipeline_count{branch=\"dev\",pipeline=\"total\",repo=\"crow-ci/crow\",status=\"success\"} 3\n# HELP crow_pipeline_time Build time.\n# TYPE crow_pipeline_time gauge\ncrow_pipeline_time{branch=\"main\",pipeline=\"total\",repo=\"crow-ci/crow\",status=\"success\"} 116\ncrow_pipeline_time{branch=\"dev\",pipeline=\"total\",repo=\"crow-ci/crow\",status=\"success\"} 155\n# HELP crow_pipeline_total_count Total number of builds.\n# TYPE crow_pipeline_total_count gauge\ncrow_pipeline_total_count 1025\n# HELP crow_pending_steps Total number of pending pipeline steps.\n# TYPE crow_pending_steps gauge\ncrow_pending_steps 0\n# HELP crow_repo_count Total number of repos.\n# TYPE crow_repo_count gauge\ncrow_repo_count 9\n# HELP crow_running_steps Total number of running pipeline steps.\n# TYPE crow_running_steps gauge\ncrow_running_steps 0\n# HELP crow_user_count Total number of users.\n# TYPE crow_user_count gauge\ncrow_user_count 1\n# HELP crow_waiting_steps Total number of pipeline waiting on deps.\n# TYPE crow_waiting_steps gauge\ncrow_waiting_steps 0\n# HELP crow_worker_count Total number of workers.\n# TYPE crow_worker_count gauge\ncrow_worker_count 4\n</code></pre>"},{"location":"configuration/server/#ssl","title":"SSL","text":"<p>Tip</p> <p>Using a reverse proxy instead of configuring SSL within Crow provides more flexibility and security and adheres more to \"best practices\" for deploying applications.</p> <p>To enable Crow to terminate TLS directly, the following settings are available:</p> <pre><code>CROW_SERVER_CERT=/etc/certs/crow.example.com/server.crt\nCROW_SERVER_KEY=/etc/certs/crow.example.com/server.key\n</code></pre> <p>SSL support is provided using the ListenAndServeTLS function from the Go standard library.</p>"},{"location":"configuration/server/#container-configuration","title":"Container configuration","text":"<p>In addition to the ports shown in the docker-compose installation, port 443 must be exposed:</p> <pre><code> services:\n   crow-server:\n     [...]\n     ports:\n+      - 80:80\n+      - 443:443\n       - 9000:9000\n</code></pre> <p>Additionally, the certificate and key must be mounted and referenced:</p> <pre><code> services:\n   crow-server:\n     environment:\n+      - CROW_SERVER_CERT=/etc/certs/crow.example.com/server.crt\n+      - CROW_SERVER_KEY=/etc/certs/crow.example.com/server.key\n     volumes:\n+      - /etc/certs/crow.example.com/server.crt:/etc/certs/crow.example.com/server.crt\n+      - /etc/certs/crow.example.com/server.key:/etc/certs/crow.example.com/server.key\n</code></pre>"},{"location":"configuration/server/#logging","title":"Logging","text":"<p>The following env vars apply to logging configuration:</p> <pre><code># default 'info'\nCROW_LOG_LEVEL\n# default 'stderr'\nCROW_LOG_FILE\n# default 'false'\nCROW_DATABASE_LOG\n# default 'false'\nCROW_DATABASE_LOG_SQL\n# default 'database'\nCROW_LOG_STORE\n# not set\nCROW_LOG_STORE_FILE_PATH\n</code></pre>"},{"location":"configuration/server/#server-agent","title":"Server &amp; Agent","text":"<p>By default, Crow streams the server and agent output to <code>stderr</code> and does not persist it.</p> <p>Note</p> <p>There is a difference between Server/Agent logs and Pipeline logs. The former are the logs describing the application runtime itself, the latter are the logs from the executed pipelines.</p> <p>Setting <code>CROW_LOG_FILE</code> alongside with <code>CROW_LOG_STORE_FILE_PATH</code> enables file-based logging.</p> <p>If <code>CROW_DATABASE_LOG=true</code> is set, logs are written into the configured database.</p> <p>Warning</p> <p>Database logging might quickly increase the size of the DB, depending on the chosen log level. It is recommended to use file-based logging with automatic log-rotation (not configured automatically).</p>"},{"location":"configuration/server/#pipeline-logs","title":"Pipeline logs","text":"<p>Pipeline execution logs are stored by default alongside a pipeline configuration in the configured database. Depending on the amount of pipelines and their output, this can fill up the database over time.</p> <p>An alternative is store logs in an external file which can possibly be auto-rotated:</p> <pre><code>CROW_LOG_STORE=file\nCROW_LOG_STORE_FILE_PATH=&lt;path&gt;\n</code></pre> <p>Info</p> <p>Support for external S3-based logging is planned.</p>"},{"location":"configuration/server/#external-configuration-api","title":"External configuration API","text":""},{"location":"configuration/server/#introduction","title":"Introduction","text":"<p>To provide additional management and preprocessing capabilities for pipeline configurations, Crow supports an HTTP API which can be enabled to call an external config service.</p> <p>Before the run or restart of any pipeline Crow will make a POST request to an external HTTP API sending the current repository, build information and all current config files retrieved from the repository. The external API can then send back new pipeline configurations that will be used immediately or respond with HTTP 204 to tell the system to use the existing configuration.</p> <p>Every request sent by Crow is signed using a http-signature by a private key (ed25519) generated on the first start of the Crow server. You can get the public key for the verification of the http-signature from http(s)://your-woodpecker-server/api/signature/public-key.</p> <p>A simplistic example configuration service can be found here.</p> <p>Warning</p> <p>The external config service must be trusted as it is receiving secret information about the repository and pipeline and has the ability to change pipeline configs that could potentially execute malicious tasks.</p>"},{"location":"configuration/server/#configuration","title":"Configuration","text":"<pre><code>CROW_CONFIG_SERVICE_ENDPOINT=https://example.com/ciconfig\n</code></pre> <p>Exemplary request from Crow:</p> <pre><code>{\n  \"repo\": {\n    \"id\": 100,\n    \"uid\": \"\",\n    \"user_id\": 0,\n    \"namespace\": \"\",\n    \"name\": \"woodpecker-test-pipe\",\n    \"slug\": \"\",\n    \"scm\": \"git\",\n    \"git_http_url\": \"\",\n    \"git_ssh_url\": \"\",\n    \"link\": \"\",\n    \"default_branch\": \"\",\n    \"private\": true,\n    \"visibility\": \"private\",\n    \"active\": true,\n    \"config\": \"\",\n    \"trusted\": false,\n    \"protected\": false,\n    \"ignore_forks\": false,\n    \"ignore_pulls\": false,\n    \"cancel_pulls\": false,\n    \"timeout\": 60,\n    \"counter\": 0,\n    \"synced\": 0,\n    \"created\": 0,\n    \"updated\": 0,\n    \"version\": 0\n  },\n  \"pipeline\": {\n    \"author\": \"myUser\",\n    \"author_avatar\": \"https://myforge.com/avatars/d6b3f7787a685fcdf2a44e2c685c7e03\",\n    \"author_email\": \"my@email.com\",\n    \"branch\": \"main\",\n    \"changed_files\": [\"some-file-name.txt\"],\n    \"commit\": \"2fff90f8d288a4640e90f05049fe30e61a14fd50\",\n    \"created_at\": 0,\n    \"deploy_to\": \"\",\n    \"enqueued_at\": 0,\n    \"error\": \"\",\n    \"event\": \"push\",\n    \"finished_at\": 0,\n    \"id\": 0,\n    \"link_url\": \"https://myforge.com/myUser/woodpecker-testpipe/commit/2fff90f8d288a4640e90f05049fe30e61a14fd50\",\n    \"message\": \"test old config\\n\",\n    \"number\": 0,\n    \"parent\": 0,\n    \"ref\": \"refs/heads/main\",\n    \"refspec\": \"\",\n    \"clone_url\": \"\",\n    \"reviewed_at\": 0,\n    \"reviewed_by\": \"\",\n    \"sender\": \"myUser\",\n    \"signed\": false,\n    \"started_at\": 0,\n    \"status\": \"\",\n    \"timestamp\": 1645962783,\n    \"title\": \"\",\n    \"updated_at\": 0,\n    \"verified\": false\n  },\n  \"netrc\": {\n    \"machine\": \"https://example.com\",\n    \"login\": \"user\",\n    \"password\": \"password\"\n  }\n}\n</code></pre> <p>Exemplary response:</p> <pre><code>{\n  \"configs\": [\n    {\n      \"name\": \"central-override\",\n      \"data\": \"steps:\\n  - name: backend\\n    image: alpine\\n    commands:\\n      - echo \\\"Hello there from ConfigAPI\\\"\\n\"\n    }\n  ]\n}\n</code></pre>"},{"location":"development/","title":"Index","text":"<p>WIP</p>"},{"location":"development/#images","title":"Images","text":""},{"location":"development/#documentation","title":"Documentation","text":""},{"location":"ecosystem/","title":"Index","text":"<p>WIP</p>"},{"location":"ecosystem/community/","title":"Community Assets","text":"<p>WIP</p>"},{"location":"installation/","title":"Index","text":""},{"location":"installation/#general","title":"General","text":"<p>Crow consists out of essential components (the \"server\" and the \"agent\") and an optional one (the \"autoscaler\").</p> <p>The server provides the UI, handles webhook requests to the underlying forge, serves the API and parses the pipeline configurations from the YAML files.</p> <p>The agent executes the pipelines using a specific backend (<code>docker</code>, <code>kubernetes</code>, <code>local</code>) and connects to the server via GRPC. Multiple agents can coexist besides each other, allowing to fine-tune job limits, backend choice and other agent-related settings for a single instance.</p> <p>The autoscaler allows spinning up new VMs on a cloud provider of choice to process pending builds. After the builds finished, the VMs are destroyed again (after a short transition time).</p> <p>Crow ships and uses a SQLite DB by default. For larger instances it is recommended to use it with a Postgres or MariaDB instance.<sup>1</sup></p> <p>Note</p> <p>The deployment of an external database is not covered here. There are many existing public guides for deploying databases. An alternative option is to use a managed DB service from a Cloud provider. If you are unsure what you need and if Crow is a good fit for you in general, you can also proceed with the SQLite DB first and decide later.</p> <p>There are currently two official ways<sup>2</sup> how to install Crow:</p> <ul> <li>Via <code>docker-compose</code> for single servers.</li> <li>Via <code>helm</code> for Kubernetes.</li> </ul>"},{"location":"installation/#crow-agent-secret","title":"Crow agent secret","text":"<p>To allow secure communication between the server and agent via GRPC, a token is required.</p> <p>There are two ways types of tokens:</p> <ul> <li>System token</li> <li>Agent token</li> </ul> <p>When using the Helm chart, a Kubernetes secret containing an agent token is created automatically. This token is then used by all agents which have access to this secret. In the best case, no further configuration is required.</p>"},{"location":"installation/#system-token","title":"System token","text":"<p>The system token is set via the env var <code>CROW_AGENT_SECRET</code> for both server and agent. There can only ever be one system token at the same time, therefore.</p> <p>If a system token is set, the registration process is as follows:</p> <ol> <li>The first time the agent communicates with the server, it is using the system token</li> <li>The server registers the agent in its database and generates a unique ID which is then sent back to the agent</li> <li>The agent stores the received ID in a config file (path is defined by <code>CROW_AGENT_CONFIG_FILE</code>)</li> <li>At the subsequent starts of the agent, it uses this token and its received ID to identify itself to the server</li> </ol> <p>Info</p> <p>If the ID is not stored/persisted in <code>CROW_AGENT_CONFIG_FILE</code> and the agent connects with a matching agent token, a new agent is registered in the DB and the UI. This will happen every time the agent container is restarted. While this is not an issue at runtime, the list of registered agents will grow and leave behind \"zombie\" agents which are registered in the DB but not active anymore. It is therefore recommended to persist <code>CROW_AGENT_CONFIG_FILE</code> to ensure idempotent agent registrations.</p>"},{"location":"installation/#agent-token","title":"Agent token","text":"<p>Agent tokens are created in the UI of the server (<code>Settings -&gt; Agents -&gt; Add agent</code>). This is an alternative way to tell the server about persistent agents and their possible connections.</p> <p>Agent tokens can be handed over to individual agents via <code>crow_AGENT_SECRET</code>, making it possible to register additional unique agents.</p> <p></p> <p>Registration of a new agent through UI</p>"},{"location":"installation/#image-tags","title":"Image tags","text":"<p>Info</p> <p>No <code>latest</code> tag exists to prevent accidental major version upgrades. Either use a Semver tag or one of the rolling major/minor version tags. Alternatively, the <code>dev</code> tag can be used for rolling builds from the <code>main</code> branch.</p> <ul> <li><code>vX.Y.Z</code>: SemVer tags for specific releases, no entrypoint shell (scratch image)<ul> <li><code>vX.Y</code></li> <li><code>vX</code></li> </ul> </li> <li><code>vX.Y.Z-alpine</code>: SemVer tags for specific releases, rootless for Server and CLI<ul> <li><code>vX.Y-alpine</code></li> <li><code>vX-alpine</code></li> </ul> </li> <li><code>dev</code>: Built from the <code>main</code> branch<ul> <li><code>dev-&lt;hash&gt;</code></li> </ul> </li> <li><code>pull_&lt;PR_ID&gt;</code>: Images built from Pull Request branches.</li> </ul>"},{"location":"installation/#image-registries","title":"Image registries","text":"<p>Images are currently solely provided through the GitHub Container Registry (ghcr.io).</p> <p>Info</p> <p>If there funds available to cover a DockerHub team subscription, images will also be there.</p> <ul> <li> <p>crow-server (ghcr.io)</p> </li> <li> <p>crow-agent (ghcr.io)</p> </li> <li> <p>crow-cli (ghcr.io)</p> </li> <li> <p>crow-autoscaler (ghcr.io)</p> </li> </ul> <ol> <li> <p>This is primarily because Crow (still) stores pipeline logs in the DB. A refactoring to storing these outside the DB by default is planned but now yet implemented.\u00a0\u21a9</p> </li> <li> <p>An Ansible role is in the works.\u00a0\u21a9</p> </li> </ol>"},{"location":"installation/docker-compose/","title":"Docker compose","text":"<p>This exemplary docker-compose setup shows the deployment of a Crow instance connected to GitHub (<code>CROW_GITHUB=true</code>). If you are using another forge, please change this including the respective secret settings.</p> <p>It creates persistent volumes for the server and agent config directories. The bundled SQLite DB is stored in <code>/var/lib/crow</code> and is the most important part to be persisted as it holds all users and repository information.</p> <p>The server uses the default port 8000 and gets exposed to the host here, so Crow can be accessed through this port on the host or by a reverse proxy sitting in front of it.</p> <p>Information</p> <p>The deployment of <code>crow-autoscaler</code> is optional. Only a brief skeleton is added below for demonstration purposes. Please check the Autoscaler documentation and decide whether or not the Autoscaler is a good fit for your environment. It also contains the information how to configure the Autoscaler in detail.</p> <pre><code>services:\n  crow-server:\n    image: ghcr.io/crowci/crow-server:&lt;tag&gt;\n    ports:\n      - 8000:8000\n    volumes:\n      - crow-server:/var/lib/crow/\n    environment:\n      - CROW_OPEN=true\n      - CROW_HOST=${CROW_HOST}\n      - CROW_GITHUB=true\n      - CROW_GITHUB_CLIENT=${CROW_GITHUB_CLIENT}\n      - CROW_GITHUB_SECRET=${CROW_GITHUB_SECRET}\n      - CROW_AGENT_SECRET=${CROW_AGENT_SECRET}\n\n  crow-agent:\n    image: ghcr.io/crowci/crow-agent:&lt;tag&gt;\n    restart: always\n    depends_on:\n      - crow-server\n    volumes:\n      - crow-agent:/etc/crow\n      - /var/run/docker.sock:/var/run/docker.sock\n    environment:\n      - CROW_SERVER=crow-server:9000\n      - CROW_AGENT_SECRET=${CROW_AGENT_SECRET}\n\n  # OPTIONAL\n  crow-autoscaler:\n    image: ghcr.io/crowci/crow-autoscaler:&lt;tag&gt;\n    restart: always\n    depends_on:\n      - crow-server\n    environment:\n      - CROW_SERVER=https://your-crow-server.com\n      - CROW_TOKEN=${CROW_TOKEN}\n      - CROW_MIN_AGENTS=0\n      - CROW_MAX_AGENTS=3\n      - CROW_WORKFLOWS_PER_AGENT=2\n      - CROW_GRPC_ADDR=https://grpc.your-crow-server.com\n      - CROW_GRPC_SECURE=true\n      - CROW_PROVIDER=hetznercloud\n      - CROW_HETZNERCLOUD_API_TOKEN=${CROW_HETZNERCLOUD_API_TOKEN}\n</code></pre>"},{"location":"installation/helm/","title":"Helm","text":""},{"location":"installation/helm/#installation","title":"Installation","text":"<p>Crow provides a Helm chart for Kubernetes environments:</p> <pre><code>helm repo add crowci oci://ghcr.io/crowci/helm\nhelm install crow crowci/crow\n</code></pre> <p>Note</p> <p>The Crow CI Autoscaler is not needed in Kubernetes environments. Kubernetes provides \"native\" ways for autoscaling nodes which should be used instead.</p>"},{"location":"installation/helm/#metrics","title":"Metrics","text":"<p>To enable metrics gathering, set the following in <code>values.yml</code>:</p> <pre><code>metrics:\n  enabled: true\n  port: 9001\n</code></pre> <p>This activates the <code>/metrics</code> endpoint on port 9001 without authentication. This port is not exposed externally by default. Use the instructions at Prometheus if you want to enable authenticated external access to metrics.</p> <p>To enable both Prometheus pod monitoring discovery, set:</p> <pre><code>prometheus:\n  podmonitor:\n    enabled: true\n    interval: 60s\n    labels: {}\n</code></pre> <p>If you are not receiving metrics after following the steps above, verify that your Prometheus configuration includes your namespace explicitly in the <code>podMonitorNamespaceSelector</code> or that the selectors are disabled:</p> <pre><code># Search all available namespaces\npodMonitorNamespaceSelector:\n  matchLabels: {}\n# Enable all available pod monitors\npodMonitorSelector:\n  matchLabels: {}\n</code></pre>"},{"location":"installation/migration/","title":"Migration from other apps","text":"<p>WIP</p>"},{"location":"installation/proxy/","title":"Reverse proxy setup","text":"<p>In the following, different reverse proxy setups are given (in alphabetical order) to make Crow work behind a reverse proxy:</p>"},{"location":"installation/proxy/#apache","title":"Apache","text":"<p>The following modules are required:</p> <ul> <li><code>proxy</code></li> <li><code>proxy_http</code></li> </ul> <pre><code>ProxyPreserveHost On\n\nRequestHeader set X-Forwarded-Proto \"https\"\n\nProxyPass / http://127.0.0.1:8000/\nProxyPassReverse / http://127.0.0.1:8000/\n</code></pre>"},{"location":"installation/proxy/#caddy","title":"Caddy","text":"<pre><code># WebUI and API\ncrow.example.com {\n  reverse_proxy crow-server:8000\n}\n\n# expose gRPC\ncrow-agent.example.com {\n  reverse_proxy h2c://crow-server:9000\n}\n</code></pre> <p>Info</p> <p>The above configuration shows how to create reverse-proxies for server and agent communication. If the agent is configured to use SSL, do not forget to enable <code>CROW_GRPC_SECURE</code>.</p>"},{"location":"installation/proxy/#nginx","title":"Nginx","text":"<pre><code>server {\n    listen 80;\n    server_name crow.example.com;\n\n    location / {\n        proxy_set_header X-Forwarded-For $remote_addr;\n        proxy_set_header X-Forwarded-Proto $scheme;\n        proxy_set_header Host $http_host;\n\n        proxy_pass http://127.0.0.1:8000;\n        proxy_redirect off;\n        proxy_http_version 1.1;\n        proxy_buffering off;\n\n        chunked_transfer_encoding off;\n    }\n}\n</code></pre> <p>Info</p> <p>This does not cover an SSL configuration with NGINX but only shows how to properly forward incoming requests through NGINX to Crow.</p>"},{"location":"installation/proxy/#ngrok","title":"Ngrok","text":"<p>Start <code>ngrok</code> using the designed Crow port, e.g. <code>ngrok http 8000</code>. This will return a response similar to the following</p> <p>Set <code>CROW_HOST</code> to the returned URL and (re)start Crow.</p>"},{"location":"installation/proxy/#tunnelmole","title":"Tunnelmole","text":"<p>Start tunnelmole using the designed Crow port, e.g. <code>tmole 8000</code>. This will return a response similar to the following</p> <pre><code>tmole 8000\nhttp://bvdo5f-ip-49-183-170-144.tunnelmole.net is forwarding to localhost:8000\nhttps://bvdo5f-ip-49-183-170-144.tunnelmole.net is forwarding to localhost:8000\n</code></pre> <p>Set <code>CROW_HOST</code> to the returned URL (e.g. exx.tunnelmole.net) and (re)start Crow.</p>"},{"location":"installation/proxy/#traefik","title":"Traefik","text":"<p>To install the crow server behind a Traefik load balancer, both the http and the gRPC ports must be exposed and configured.</p> <p>Here is a comprehensive example, which uses <code>traefik</code> running via docker compose and applies TLS termination and automatic redirection from http to https.</p> <pre><code>services:\n  server:\n    image: ghcr.io/crowci/crow-server:latest\n    environment:\n      # Crow settings ...\n\n    networks:\n      - dmz # externally defined network, so that traefik can connect to the server\n    volumes:\n      - crow-server-data:/var/lib/crow/\n\n    deploy:\n      labels:\n        - traefik.enable=true\n\n        # web server\n        - traefik.http.services.crow-service.loadbalancer.server.port=8000\n\n        - traefik.http.routers.crow-secure.rule=Host(`cd.your-domain.com`)\n        - traefik.http.routers.crow-secure.tls=true\n        - traefik.http.routers.crow-secure.tls.certresolver=letsencrypt\n        - traefik.http.routers.crow-secure.entrypoints=web-secure\n        - traefik.http.routers.crow-secure.service=crow-service\n\n        - traefik.http.routers.crow.rule=Host(`cd.your-domain.com`)\n        - traefik.http.routers.crow.entrypoints=web\n        - traefik.http.routers.crow.service=crow-service\n\n        - traefik.http.middlewares.crow-redirect.redirectscheme.scheme=https\n        - traefik.http.middlewares.crow-redirect.redirectscheme.permanent=true\n        - traefik.http.routers.crow.middlewares=crow-redirect@docker\n\n        #  gRPC service\n        - traefik.http.services.crow-grpc.loadbalancer.server.port=9000\n        - traefik.http.services.crow-grpc.loadbalancer.server.scheme=h2c\n\n        - traefik.http.routers.crow-grpc-secure.rule=Host(`crow-grpc.your-domain.com`)\n        - traefik.http.routers.crow-grpc-secure.tls=true\n        - traefik.http.routers.crow-grpc-secure.tls.certresolver=letsencrypt\n        - traefik.http.routers.crow-grpc-secure.entrypoints=web-secure\n        - traefik.http.routers.crow-grpc-secure.service=crow-grpc\n\n        - traefik.http.routers.crow-grpc.rule=Host(`crow-grpc.your-domain.com`)\n        - traefik.http.routers.crow-grpc.entrypoints=web\n        - traefik.http.routers.crow-grpc.service=crow-grpc\n\n        - traefik.http.middlewares.crow-grpc-redirect.redirectscheme.scheme=https\n        - traefik.http.middlewares.crow-grpc-redirect.redirectscheme.permanent=true\n        - traefik.http.routers.crow-grpc.middlewares=crow-grpc-redirect@docker\n\nnetworks:\n  dmz:\n    external: true\n</code></pre>"},{"location":"plugins/","title":"Index","text":"<p>WIP</p>"},{"location":"usage/","title":"Index","text":""},{"location":"usage/#pipelines","title":"Pipelines","text":""},{"location":"usage/#essential-elements","title":"Essential elements","text":""},{"location":"usage/#secrets","title":"Secrets","text":""},{"location":"usage/#environment-variables","title":"Environment Variables","text":""},{"location":"usage/#optional-elements","title":"Optional elements","text":""},{"location":"usage/#registries","title":"Registries","text":""},{"location":"usage/#services","title":"Services","text":"<p>Woodpecker provides a services section in the YAML file used for defining service containers. The below configuration composes database and cache containers.</p> <p>Services are accessed using custom hostnames. In the example below, the MySQL service is assigned the hostname <code>database</code> and is available at <code>database:3306</code>.</p> <pre><code>steps:\n  - name: build\n    image: golang\n    commands:\n      - go build\n      - go test\n\nservices:\n  - name: database\n    image: mysql\n\n  - name: cache\n    image: redis\n</code></pre> <p>You can define a port and a protocol explicitly:</p> <pre><code>services:\n  - name: database\n    image: mysql\n    ports:\n      - 3306\n\n  - name: wireguard\n    image: wg\n    ports:\n      - 51820/udp\n</code></pre>"},{"location":"usage/#configuration","title":"Configuration","text":"<p>Service containers generally expose environment variables to customize service startup such as default usernames, passwords and ports. Please see the official image documentation to learn more.</p> <pre><code> services:\n   - name: database\n     image: mysql\n+    environment:\n+      - MYSQL_DATABASE=test\n+      - MYSQL_ALLOW_EMPTY_PASSWORD=yes\n\n   - name: cache\n     image: redis\n</code></pre>"},{"location":"usage/#detachment","title":"Detachment","text":"<p>Service and long running containers can also be included in the pipeline section of the configuration using the detach parameter without blocking other steps. This should be used when explicit control over startup order is required.</p> <pre><code> steps:\n   - name: build\n     image: golang\n     commands:\n       - go build\n       - go test\n\n   - name: database\n     image: redis\n+    detach: true\n\n   - name: test\n     image: golang\n     commands:\n       - go test\n</code></pre> <p>Containers from detached steps will terminate when the pipeline ends.</p>"},{"location":"usage/#initialization","title":"Initialization","text":"<p>Service containers require time to initialize and begin to accept connections. If you are unable to connect to a service you may need to wait a few seconds or implement a backoff.</p> <pre><code> steps:\n   - name: test\n     image: golang\n     commands:\n+      - sleep 15\n       - go get\n       - go test\n\n services:\n   - name: database\n     image: mysql\n</code></pre>"},{"location":"usage/#full-services-example","title":"Full \"Services\" example","text":"<pre><code>services:\n  - name: database\n    image: mysql\n    environment:\n      - MYSQL_DATABASE=test\n      - MYSQL_ROOT_PASSWORD=example\nsteps:\n  - name: get-version\n    image: ubuntu\n    commands:\n      - ( apt update &amp;&amp; apt dist-upgrade -y &amp;&amp; apt install -y mysql-client 2&gt;&amp;1 )&gt; /dev/null\n      - sleep 30s # need to wait for mysql-server init\n      - echo 'SHOW VARIABLES LIKE \"version\"' | mysql -u root -h database test -p example\n</code></pre>"},{"location":"usage/#volumes","title":"Volumes","text":""},{"location":"usage/#cron-jobs","title":"CRON jobs","text":""},{"location":"usage/#project-settings","title":"Project settings","text":""},{"location":"usage/#miscellaneous","title":"Miscellaneous","text":""},{"location":"usage/#warnings-error-linter","title":"Warnings &amp; Error Linter","text":""},{"location":"usage/#advanced","title":"Advanced","text":""}]}